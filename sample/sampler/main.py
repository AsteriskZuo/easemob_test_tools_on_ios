#!/usr/bin/env python3
"""
IM æ•°æ®æŠ½æ ·å·¥å…·ï¼ˆç­‰åˆ†åˆ‡å‰²ï¼‰

å°†æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ JSONL æ•°æ®æ–‡ä»¶ç­‰åˆ†åˆ‡å‰²ä¸º N ä»½å°æ–‡ä»¶ï¼Œ
ä¿æŒæ•°æ®çš„æ—¶åºè¿ç»­æ€§ï¼Œé€‚ç”¨äº LZ4 å‹ç¼©ç‡æµ‹è¯•æŠ½æ ·ã€‚

ç”¨æ³•:
    uv run main.py <æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„> [é€‰é¡¹]

ç¤ºä¾‹:
    uv run main.py ../../sdkTest/tmp --parts 100
    uv run main.py ../../sdkTest/tmp --parts 50 --output-dir ./my_output
"""

import sys
import time
from pathlib import Path


def format_bytes(n: float) -> str:
    """æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
    if n < 1024:
        return f"{n:.0f} B"
    elif n < 1024 * 1024:
        return f"{n / 1024:.1f} KB"
    elif n < 1024 * 1024 * 1024:
        return f"{n / (1024 * 1024):.2f} MB"
    else:
        return f"{n / (1024 * 1024 * 1024):.2f} GB"


def get_data_files(dir_path: Path) -> list[Path]:
    """è·å–æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ•°æ®æ–‡ä»¶ï¼ˆæ’é™¤éšè—æ–‡ä»¶ï¼‰ï¼ŒæŒ‰åç§°æ’åº"""
    files = []
    for entry in sorted(dir_path.iterdir()):
        if entry.is_file() and not entry.name.startswith("."):
            files.append(entry)
    return files


def count_total_lines(data_files: list[Path], total_file_size: int) -> int:
    """ç¬¬ä¸€éï¼šæµå¼ç»Ÿè®¡æ€»è¡Œæ•°"""
    print("ğŸ“Š ç¬¬ä¸€éï¼šç»Ÿè®¡æ€»è¡Œæ•°...")
    total_lines = 0
    bytes_read = 0
    last_progress_time = time.time()

    for file_idx, filepath in enumerate(data_files):
        with open(filepath, "r", encoding="utf-8") as f:
            for raw_line in f:
                if raw_line.strip():
                    total_lines += 1
                bytes_read += len(raw_line.encode("utf-8"))

                now = time.time()
                if now - last_progress_time >= 1.0:
                    pct = bytes_read / total_file_size * 100 if total_file_size else 0
                    print(
                        f"\r  â³ è¿›åº¦: {pct:.1f}% | "
                        f"æ–‡ä»¶ {file_idx + 1}/{len(data_files)} | "
                        f"å·²ç»Ÿè®¡ {total_lines:,} è¡Œ",
                        end="",
                        flush=True,
                    )
                    last_progress_time = now

    print(f"\r  âœ… æ€»è¡Œæ•°: {total_lines:,}{' ' * 40}")
    return total_lines


def split_files(
    data_files: list[Path],
    total_lines: int,
    total_file_size: int,
    parts: int,
    output_dir: Path,
) -> None:
    """ç¬¬äºŒéï¼šæµå¼è¯»å–å¹¶æŒ‰è¡Œæ•°åˆ‡å‰²å†™å…¥"""
    lines_per_part = total_lines // parts
    remainder = total_lines % parts

    print(f"\nâœ‚ï¸  ç¬¬äºŒéï¼šåˆ‡å‰²ä¸º {parts} ä»½...")
    print(f"  æ¯ä»½çº¦ {lines_per_part:,} è¡Œ", end="")
    if remainder > 0:
        print(f"ï¼ˆå‰ {remainder} ä»½å¤š 1 è¡Œï¼‰")
    else:
        print()

    output_dir.mkdir(parents=True, exist_ok=True)

    current_part = 1
    lines_in_current_part = 0
    # å‰ remainder ä»½æ¯ä»½å¤šåˆ† 1 è¡Œ
    current_part_limit = lines_per_part + (1 if current_part <= remainder else 0)
    digits = len(str(parts))
    out_filename = f"part_{current_part:0{digits}d}.jsonl"
    out_file = open(output_dir / out_filename, "w", encoding="utf-8")

    global_line = 0
    bytes_read = 0
    last_progress_time = time.time()

    for file_idx, filepath in enumerate(data_files):
        with open(filepath, "r", encoding="utf-8") as f:
            for raw_line in f:
                stripped = raw_line.strip()
                if not stripped:
                    continue

                bytes_read += len(raw_line.encode("utf-8"))
                global_line += 1

                out_file.write(stripped + "\n")
                lines_in_current_part += 1

                # å½“å‰åˆ†ç‰‡æ»¡äº†ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª
                if lines_in_current_part >= current_part_limit and current_part < parts:
                    out_file.close()
                    current_part += 1
                    lines_in_current_part = 0
                    current_part_limit = lines_per_part + (
                        1 if current_part <= remainder else 0
                    )
                    out_filename = f"part_{current_part:0{digits}d}.jsonl"
                    out_file = open(output_dir / out_filename, "w", encoding="utf-8")

                # è¿›åº¦æ˜¾ç¤º
                now = time.time()
                if now - last_progress_time >= 1.0:
                    pct = bytes_read / total_file_size * 100 if total_file_size else 0
                    print(
                        f"\r  â³ è¿›åº¦: {pct:.1f}% | "
                        f"æ­£åœ¨å†™å…¥ part {current_part}/{parts} | "
                        f"å·²å¤„ç† {global_line:,} è¡Œ",
                        end="",
                        flush=True,
                    )
                    last_progress_time = now

    out_file.close()
    print(f"\r  âœ… åˆ‡å‰²å®Œæˆï¼å…± {current_part} ä»½{' ' * 40}")


def main():
    # è§£æå‚æ•°
    args = sys.argv[1:]
    if not args or args[0] in ("-h", "--help"):
        print("ç”¨æ³•: uv run main.py <æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„> [é€‰é¡¹]")
        print()
        print("é€‰é¡¹:")
        print("  --parts N        åˆ‡å‰²ä»½æ•°ï¼ˆé»˜è®¤ 100ï¼‰")
        print("  --output-dir DIR è¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆé»˜è®¤ ./outputï¼‰")
        print()
        print("ç¤ºä¾‹:")
        print("  uv run main.py ../../sdkTest/tmp --parts 100")
        print("  uv run main.py ../../sdkTest/tmp --parts 50 --output-dir ./my_output")
        sys.exit(0 if args else 1)

    input_dir = args[0]
    parts = 100
    output_dir = "./output"

    i = 1
    while i < len(args):
        if args[i] == "--parts" and i + 1 < len(args):
            parts = int(args[i + 1])
            i += 2
        elif args[i] == "--output-dir" and i + 1 < len(args):
            output_dir = args[i + 1]
            i += 2
        else:
            print(f"âŒ æœªçŸ¥å‚æ•°: {args[i]}")
            sys.exit(1)

    if parts < 1:
        print("âŒ --parts å¿…é¡» >= 1")
        sys.exit(1)

    dir_path = Path(input_dir)
    if not dir_path.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_dir}")
        sys.exit(1)
    if not dir_path.is_dir():
        print(f"âŒ ä¸æ˜¯æ–‡ä»¶å¤¹: {input_dir}")
        sys.exit(1)

    data_files = get_data_files(dir_path)
    if not data_files:
        print(f"âŒ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ•°æ®æ–‡ä»¶: {input_dir}")
        sys.exit(1)

    total_file_size = sum(f.stat().st_size for f in data_files)
    out_path = Path(output_dir)

    print("=" * 60)
    print("  âœ‚ï¸  IM æ•°æ®ç­‰åˆ†åˆ‡å‰²å·¥å…·")
    print("=" * 60)
    print(f"\nğŸ“‚ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“„ æ•°æ®æ–‡ä»¶: {len(data_files)} ä¸ª")
    print(f"ğŸ“¦ æ€»å¤§å°:   {format_bytes(total_file_size)}")
    print(f"ğŸ”¢ åˆ‡å‰²ä»½æ•°: {parts}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {out_path.resolve()}\n")

    # ç¬¬ä¸€éï¼šç»Ÿè®¡æ€»è¡Œæ•°
    total_lines = count_total_lines(data_files, total_file_size)

    if total_lines < parts:
        print(f"âš ï¸  æ€»è¡Œæ•° ({total_lines:,}) å°‘äºåˆ‡å‰²ä»½æ•° ({parts})ï¼Œè°ƒæ•´ä¸º {total_lines} ä»½")
        parts = total_lines

    # ç¬¬äºŒéï¼šåˆ‡å‰²
    split_files(data_files, total_lines, total_file_size, parts, out_path)

    # è¾“å‡ºæ¦‚è¦
    print()
    print("=" * 60)
    print("  ğŸ“‹ åˆ‡å‰²ç»“æœ")
    print("=" * 60)
    print(f"\n  è¾“å‡ºç›®å½•:   {out_path.resolve()}")
    print(f"  æ€»è¡Œæ•°:     {total_lines:,}")
    print(f"  åˆ‡å‰²ä»½æ•°:   {parts}")
    print(f"  æ¯ä»½çº¦:     {total_lines // parts:,} è¡Œ")
    print()

    # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
    output_files = sorted(out_path.glob("part_*.jsonl"))
    if len(output_files) <= 10:
        for fp in output_files:
            print(f"  {fp.name:20s} {format_bytes(fp.stat().st_size):>10s}")
    else:
        for fp in output_files[:3]:
            print(f"  {fp.name:20s} {format_bytes(fp.stat().st_size):>10s}")
        print(f"  {'...':20s}")
        for fp in output_files[-3:]:
            print(f"  {fp.name:20s} {format_bytes(fp.stat().st_size):>10s}")

    print()
    print("=" * 60)
    print("  åˆ‡å‰²å®Œæˆ âœ…")
    print("=" * 60)


if __name__ == "__main__":
    main()
